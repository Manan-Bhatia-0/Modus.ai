{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook includes functions relevent for cleaning data that will later be essential for working with different algorithms and machine learning models.  \n",
    "\n",
    "*Currently takes in URL input but will be modified once more data is accumulated*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve stopwords to clean data - from NLTK library\n",
    "def get_stop_words():\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes url (temporarily) and stopwords list as input and returns a list of words OR a string from url\n",
    "# without stopwords and punctuation\n",
    "# This will later take a file or db query as an input instead of URL\n",
    "\n",
    "def retrieve_data_from_url(url, stopwords):\n",
    "    list_8 = []\n",
    "    dict_8 = {}\n",
    "    r= urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(r, 'lxml')\n",
    "    things = soup.find_all('p')\n",
    "    lst = []\n",
    "\n",
    "    for i in things:\n",
    "        i_strip = i.text.strip()\n",
    "        i_strip = re.sub(\"[^\\w\\s_\\']+\",\" \", i_strip)\n",
    "        i_strip = i_strip.lower()\n",
    "        split_text = i_strip.split(\" \")\n",
    "        lst = lst + split_text\n",
    "    return_lst = []\n",
    "    for i in range(len(lst)):\n",
    "        val = lst[i]\n",
    "        if ((val not in stopwords) and (val != \"\")):\n",
    "            return_lst.append(val)\n",
    "    return_string = ' '.join(return_lst)\n",
    "    return return_lst, return_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions\n",
    "stopwords = get_stop_words()\n",
    "cleaned_lst, cleaned_string = retrieve_data_from_url('https://en.wikipedia.org/wiki/Natural_language_processing', stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing nlp subfield linguistics computer science artificial intelligence concerned interactions computers human language particular program computers process analyze large amounts natural language data goal computer capable understanding contents documents including contextual nuances language within technology accurately extract information insights contained documents well categorize organize documents challenges natural language processing frequently involve speech recogn'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_string[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub string keep apostrophes\n",
    "String = \"hello you are cool_ don't. [45]\"\n",
    "String = re.sub(\"[^\\w\\s_\\']+\",\" \", String)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
