{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This notebook includes functions relevent for cleaning data that will later be essential for working with different algorithms and machine learning models.  \n",
    "\n",
    "*Currently takes in URL input but will be modified once more data is accumulated*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve stopwords to clean data - from NLTK library\n",
    "def get_stop_words():\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes url (temporarily) and stopwords list as input and returns a list of words OR a string from url\n",
    "# without stopwords and punctuation\n",
    "# This will later take a file or db query as an input instead of URL\n",
    "\n",
    "def retrieve_data_from_url(url, stopwords):\n",
    "    pattern = re.compile(r\"[\\w]{8}\")\n",
    "    list_8 = []\n",
    "    dict_8 = {}\n",
    "    r= urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(r, 'lxml')\n",
    "    things = soup.find_all('p')\n",
    "    lst = []\n",
    "\n",
    "    for i in things:\n",
    "        i_strip = i.text.strip()\n",
    "        i_strip = re.sub('[\\W_]+',\" \", i_strip)\n",
    "        i_strip = i_strip.lower()\n",
    "        split_text = i_strip.split(\" \")\n",
    "        lst = lst + split_text\n",
    "    return_lst = []\n",
    "    for i in range(len(lst)):\n",
    "        val = lst[i]\n",
    "        if ((val not in stopwords) and (val != \"\")):\n",
    "            return_lst.append(val)\n",
    "    return_string = ' '.join(return_lst)\n",
    "    return return_lst, return_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions\n",
    "stopwords = get_stop_words()\n",
    "cleaned_lst, cleaned_string = retrieve_data_from_url('https://en.wikipedia.org/wiki/Natural_language_processing', stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'interactions',\n",
       " 'computers',\n",
       " 'human',\n",
       " 'language',\n",
       " 'particular',\n",
       " 'program',\n",
       " 'computers',\n",
       " 'process',\n",
       " 'analyze']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_lst[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing nlp subfield linguistics computer science artificial intelligence concerned interactions computers human language particular program computers process analyze large amounts natural language data goal computer capable understanding contents documents including contextual nuances language within technology accurately extract information insights contained documents well categorize organize documents challenges natural language processing frequently involve speech recognition natural language understanding natural language generation natural language processing roots 1950s already 1950 alan turing published article titled computing machinery intelligence proposed called turing test criterion intelligence task involves automated interpretation generation natural language time articulated problem separate artificial intelligence premise symbolic nlp well summarized john searle chinese room experiment given collection rules e g chinese phrasebook questions matching'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_string[:1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
